{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Data Science (MAST30034) Tutorial 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`statsmodels` (30-45 minutes):\n",
    "- Linear Regression\n",
    "- Evaluation Metrics\n",
    "- Penalized Regression (LASSO and Ridge)\n",
    "\n",
    "`pyspark.ml` (Experimental) (15 minutes):\n",
    "- Linear Regression\n",
    "\n",
    "Project 1 Report (Remainder of Tutorial):\n",
    "- Questions\n",
    "- Ongoing feedback.\n",
    "\n",
    "Optional Content for Students:\n",
    "- Generalised Linear Models (GLM) with `statsmodels`\n",
    "- MAST30025 Revision:\n",
    "    - Lecture 4 (variable selection)\n",
    "    - LSM topic 5 (`ch05_handout`) slide 141/141\n",
    "    - An excellent explanation on Ridge / LASSO: https://www.youtube.com/watch?v=9LNpiiKCQUo (recommended at x1.25 speed)\n",
    "_________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:32:40.067237Z",
     "start_time": "2022-07-23T23:32:39.244235Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.formula.api import ols, glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:32:40.117609Z",
     "start_time": "2022-07-23T23:32:40.069375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                          int64\n",
       "tpep_pickup_datetime     datetime64[ns]\n",
       "tpep_dropoff_datetime    datetime64[ns]\n",
       "passenger_count                 float64\n",
       "trip_distance                   float64\n",
       "RatecodeID                      float64\n",
       "store_and_fwd_flag               object\n",
       "PULocationID                      int64\n",
       "DOLocationID                      int64\n",
       "payment_type                      int64\n",
       "fare_amount                     float64\n",
       "extra                           float64\n",
       "mta_tax                         float64\n",
       "tip_amount                      float64\n",
       "tolls_amount                    float64\n",
       "improvement_surcharge           float64\n",
       "total_amount                    float64\n",
       "congestion_surcharge            float64\n",
       "airport_fee                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../../data/tute_data/sample_data.parquet\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's try to predict `total_amount` using `fare_amount, tip_amount, toll_amount, trip_distance, VendorID` as predictors.\n",
    "\n",
    "Some things to take note:\n",
    "- `tip_amount` is only valid for `payment_type == 1` (card)\n",
    "- `VendorID` is categorical, with only two possible values (`1` or `2`) so we should make it boolean\n",
    "\n",
    "**Whilst you may use this as an example, please do not copy this as it is incorrect.**\n",
    "\n",
    "How so? Discuss as a class the implications of predicting `total_amount` given the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:32:40.141885Z",
     "start_time": "2022-07-23T23:32:40.122845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_amount</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>VendorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92981</th>\n",
       "      <td>24.95</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92982</th>\n",
       "      <td>11.15</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92983</th>\n",
       "      <td>42.10</td>\n",
       "      <td>28.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>6.55</td>\n",
       "      <td>9.30</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92984</th>\n",
       "      <td>15.36</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92985</th>\n",
       "      <td>11.16</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_amount  fare_amount  tip_amount  tolls_amount  trip_distance  \\\n",
       "92981         24.95         17.0        4.15          0.00           5.10   \n",
       "92982         11.15          5.5        1.85          0.00           1.00   \n",
       "92983         42.10         28.5        2.00          6.55           9.30   \n",
       "92984         15.36          9.0        2.56          0.00           2.50   \n",
       "92985         11.16          5.5        1.86          0.00           1.02   \n",
       "\n",
       "       VendorID  \n",
       "92981      True  \n",
       "92982      True  \n",
       "92983      True  \n",
       "92984      True  \n",
       "92985     False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter dataframe\n",
    "COL_FILTER = ['total_amount', 'fare_amount', 'tip_amount', 'tolls_amount', 'trip_distance', 'VendorID']\n",
    "df_filtered = df.loc[df['payment_type'] == 1, COL_FILTER].reset_index(drop=True)\n",
    "\n",
    "# same as df_filtered['VendorID'].astype(bool)\n",
    "df_filtered['VendorID'] = df_filtered['VendorID'] == 1 \n",
    "\n",
    "df_filtered.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are looking for linear relationships between our chosen response `total_amount`.   \n",
    "- Now I'm not sure what kind of life you've lived, but I'm fairly certain that we can infer that `total_amount` will have a positive linear relationship with `fare_amount`. Let's see a quick plot..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:32:40.358548Z",
     "start_time": "2022-07-23T23:32:40.143577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_filtered[['total_amount', 'fare_amount']].plot.scatter(x='fare_amount', y='total_amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, obviously this looks like an overall positive linear relationship. How might we statistically test this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `R`, we would do something like this for (Ordinary) Least Squares:\n",
    "```R\n",
    ">>> fit <- lm(total_amount~fare_amount + tip_amount + tolls_amount + trip_distance + VendorID ,data=dat_fit)\n",
    ">>> summary(fit)\n",
    "```\n",
    "```\n",
    "Call:\n",
    "lm(formula = total_amount ~ fare_amount + tip_amount + tolls_amount +\n",
    "trip_distance + VendorID, data = dat_fit)\n",
    "\n",
    "Residuals:\n",
    "Min     1Q      Median  3Q     Max\n",
    "-1.4727 -0.3295 -0.1528 0.1747 1.7975\n",
    "\n",
    "Coefficients:\n",
    "               Estimate Std. Error t value Pr(>|t|)\n",
    "(Intercept)    1.162154   0.002986 389.194  <2e-16 ***\n",
    "fare_amount    0.993388   0.000315 3153.943 <2e-16 ***\n",
    "tip_amount     1.006511   0.000826 1218.553 <2e-16 ***\n",
    "tolls_amount   0.979325   0.001285 762.428  <2e-16 ***\n",
    "trip_distance  0.011742   0.000963 12.194   <2e-16 ***\n",
    "VendorIDTRUE  -0.003125   0.002914 -1.073    0.283\n",
    "---\n",
    "Signif. codes:\n",
    "0 ^a˘A¨Y***^a˘A´Z 0.001 ^a˘A¨Y**^a˘A´Z 0.01 ^a˘A¨Y*^a˘A´Z 0.05 ^a˘A¨Y.^a˘A´Z 0.1 ^a˘A¨Y ^a˘A´Z 1\n",
    "\n",
    "Residual standard error: 0.362 on 61886 degrees of freedom\n",
    "Multiple R-squared: 0.9994,          Adjusted R-squared: 0.9994\n",
    "F-statistic: 1.953e+07 on 5 and 61886 DF, p-value: < 2.2e-16\n",
    "```\n",
    "\n",
    "Note: This example from `R` uses an older dataset hence different values to the Python output below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation Source: https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html?highlight=ols#statsmodels.regression.linear_model.OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:32:40.396543Z",
     "start_time": "2022-07-23T23:32:40.360170Z"
    }
   },
   "outputs": [],
   "source": [
    "fit = ols(\n",
    "    formula=\"total_amount ~ fare_amount + tip_amount + tolls_amount + trip_distance + VendorID\",\n",
    "    data=df_filtered\n",
    ").fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:32:40.421115Z",
     "start_time": "2022-07-23T23:32:40.398164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           total_amount   R-squared:                       0.998\n",
      "Model:                            OLS   Adj. R-squared:                  0.998\n",
      "Method:                 Least Squares   F-statistic:                 8.111e+06\n",
      "Date:                Sun, 24 Jul 2022   Prob (F-statistic):               0.00\n",
      "Time:                        09:32:40   Log-Likelihood:            -1.0380e+05\n",
      "No. Observations:               92986   AIC:                         2.076e+05\n",
      "Df Residuals:                   92980   BIC:                         2.077e+05\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept            3.6262      0.004    842.811      0.000       3.618       3.635\n",
      "VendorID[T.True]    -0.0610      0.005    -11.557      0.000      -0.071      -0.051\n",
      "fare_amount          0.9775      0.000   2849.239      0.000       0.977       0.978\n",
      "tip_amount           1.0352      0.001    928.310      0.000       1.033       1.037\n",
      "tolls_amount         1.0404      0.002    565.826      0.000       1.037       1.044\n",
      "trip_distance        0.0330      0.001     39.043      0.000       0.031       0.035\n",
      "==============================================================================\n",
      "Omnibus:                    22330.967   Durbin-Watson:                   1.386\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1435112.916\n",
      "Skew:                          -0.088   Prob(JB):                         0.00\n",
      "Kurtosis:                      22.245   Cond. No.                         44.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion Questions:\n",
    "1. Is this model good? Discuss $R^2$, AIC, and Hypothesis Testing.\n",
    "    \n",
    "2. How might we improve this model? Discuss what we can do with the current features / engineered features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:32:40.465552Z",
     "start_time": "2022-07-23T23:32:40.423197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           total_amount   R-squared:                       0.998\n",
      "Model:                            OLS   Adj. R-squared:                  0.998\n",
      "Method:                 Least Squares   F-statistic:                 1.012e+07\n",
      "Date:                Sun, 24 Jul 2022   Prob (F-statistic):               0.00\n",
      "Time:                        09:32:40   Log-Likelihood:            -1.0386e+05\n",
      "No. Observations:               92986   AIC:                         2.077e+05\n",
      "Df Residuals:                   92981   BIC:                         2.078e+05\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept         3.6071      0.004    907.201      0.000       3.599       3.615\n",
      "fare_amount       0.9774      0.000   2847.277      0.000       0.977       0.978\n",
      "tip_amount        1.0356      0.001    928.366      0.000       1.033       1.038\n",
      "tolls_amount      1.0402      0.002    565.334      0.000       1.037       1.044\n",
      "trip_distance     0.0331      0.001     39.090      0.000       0.031       0.035\n",
      "==============================================================================\n",
      "Omnibus:                    22427.464   Durbin-Watson:                   1.386\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1453509.044\n",
      "Skew:                          -0.101   Prob(JB):                         0.00\n",
      "Kurtosis:                      22.368   Cond. No.                         31.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# let's try another model without VendorID\n",
    "fitter = ols(\n",
    "    formula=\"total_amount ~ fare_amount + tip_amount + tolls_amount + trip_distance\",\n",
    "    data=df_filtered\n",
    ").fit()\n",
    "\n",
    "print(fitter.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have to values of AIC to compare with, which one is better...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:32:40.482218Z",
     "start_time": "2022-07-23T23:32:40.476949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207608.10719375586, 207739.57404300693, 'abs diff: 131.4668492510682')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.aic, fitter.aic, f\"abs diff: {abs(fitter.aic - fit.aic)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:32:40.525537Z",
     "start_time": "2022-07-23T23:32:40.510759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([207608.10719375586, 207739.57404300693],\n",
       " [207664.74841909486, 207786.77506412278])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fit.aic, fitter.aic], [fit.bic, fitter.bic]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalized Regression\n",
    "(From a machine learning perspective) Given a data distribution $\\mathcal{D}$, predefined model hypothesis class $\\mathcal{B}$, a loss function $\\ell$. The goal of machine learning (aka modelling) is to find parameter $\\beta^*$ such that,\n",
    "\n",
    "  $$\\beta^* = \\text{argmin}_{\\beta\\in\\mathcal{B}} \\mathbb{E}_{(x,y)\\in \\mathcal{D}}\\{\\ell(y, f_{\\beta}(x))\\}$$\n",
    "  \n",
    "  \n",
    "In reality, we don't have $\\mathcal{D}$, but only a dataset $\\mathbb{(X, Y)}$ where $(x_i, y_i) \\sim \\mathcal{D}$. And we empirically compute, \n",
    "\n",
    "  $$\\hat\\beta^* = \\text{argmin}_{\\beta\\in\\mathcal{B}} \\sum_{(x,y)\\in (\\mathbb{X, Y})}\\ell(y, f_{\\beta}(x))$$\n",
    "  \n",
    "  \n",
    "  In the hope that, $\\hat\\beta^*$ is close to $\\beta^*$. So for any unseen $(x, y) \\sim \\mathcal{D}$, our model is still optimal.\n",
    "  \n",
    "  \n",
    "This implies that a more complicated $\\hat\\beta^*$ (blue) might not correspond to actual optimal parameters $\\beta^*$ (green).\n",
    "  <img src=\"../../media/regularization.png\" alt=\"regularization\" style=\"width: 400px;\"/>\n",
    "In practice, a simpler model often explains ground truth better. We call the techniques to simplify model *regularization*.\n",
    "  \n",
    "  \n",
    "For linear regression model, LASSO and Ridge are two common techniques to regularize model.\n",
    "- Discussion: what is formula of $f_{\\beta}(x)$, $\\ell(\\cdot, \\cdot)$ for linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:24:46.191329Z",
     "start_time": "2022-07-23T23:24:46.181384Z"
    }
   },
   "source": [
    "## LASSO ($\\ell_1$)\n",
    "- Regularizes coefficient magnitude with $\\ell_1$ loss,\n",
    "  $$\\hat\\beta^* = \\text{argmin}_{\\beta \\in \\mathcal{B}} (\\mathbf{y}-X\\beta)^T(\\mathbf{y}-X\\beta) + \\lambda  ||\\beta||_1$$\n",
    "- LASSO encourages coefficient sparsity (setting to a value of 0).\n",
    "- Features that are collinear will result in one of them being reduced to 0 coefficient.\n",
    "- In this sense, it's quite similar to feature selection as you end up with a model that is much more simpler. \n",
    "\n",
    "## Ridge ($\\ell_2$)\n",
    "- Regularizes coefficient magnitude with $\\ell_2$ loss,\n",
    "  $$\\hat\\beta^* = \\text{argmin}_{\\beta \\in \\Beta} (\\mathbf{y}-X\\beta)^T(\\mathbf{y}-X\\beta) + \\frac{1}{2} \\lambda ||\\beta||_2^2$$\n",
    "- Ridge regression tend to shrink coefficients to a small value but not zero.\n",
    "  - Why? Can you explain this? (Tip: consider a pair of positive coefficient $\\beta=[1, \\epsilon], \\epsilon < 1$, and think about what happens to $||\\beta||_2^2$ when you subtract $\\delta \\leq \\epsilon$ from each element $\\beta$)\n",
    "- Maintaining more features, Ridge Regression is less interpretable than LASSO, but performs better in cases where there may be high multi-collinearity (i.e dependencies between attributes) or high linear correlation between certain attributes.\n",
    "- You must also ensure that we have more observations than attributes (`n > p`) as this penalty method does not drop features, leading to worse predictions. \n",
    "\n",
    "<img src=\"../../media/lasso_ridge.png\" alt=\"lassoridge\" style=\"width: 600px;\"/>\n",
    "\n",
    "### Elastic Net\n",
    "Quick overview:\n",
    "- Combines both $\\ell_1$ and $\\ell_2$ penalty,\n",
    "  $$\\hat\\beta^* = \\text{argmin}_{\\beta \\in \\mathcal{B}} (\\mathbf{y}-X\\beta)^T(\\mathbf{y}-X\\beta) + \\lambda_1 ||\\beta||_1 + \\frac{1}{2} \\lambda_2 ||\\beta||_2^2$$\n",
    "- Python implementation (glmnet):\n",
    "  - https://github.com/civisanalytics/python-glmnet/blob/master/glmnet/linear.py\n",
    "  - glmnet (hyper)parameterize the loss with $\\alpha$ and $\\lambda$ instead,\n",
    "    $$\\hat\\beta^* = \\text{argmin}_{\\beta \\in \\mathcal{B}} (\\mathbf{y}-X\\beta)^T(\\mathbf{y}-X\\beta) + \\lambda \\{\\alpha ||\\beta||_1 + \\frac{1}{2} (1-\\alpha) ||\\beta||_2^2\\}$$\n",
    "\n",
    "Question/Discussion:\n",
    "- How would you implement optimizer for the above objectives (LASSO, Ridge, Elastic Net)?\n",
    "- Do you need to standardize the input data? Why?\n",
    "  - _In your own time, make a mock dataset to demonstrate the importance for standardization._\n",
    "- Is the following pseudo-code correct? Why or why not?\n",
    "  ```R\n",
    "  mu <- mean(X)\n",
    "  sigma <- std(X)\n",
    "  X_std <- (X - mu) / sigma\n",
    "  X_train, X_test, y_train, y_test <- split(X_std, y)\n",
    "  model <- fit(y_train ~ X_train)\n",
    "  y_pred <- predict(model, X_test)\n",
    "  loss <- MSE(y_test, y_pred)\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:32:40.548546Z",
     "start_time": "2022-07-23T23:32:40.535585Z"
    }
   },
   "outputs": [],
   "source": [
    "y_cols = ['total_amount']\n",
    "x_cols = ['fare_amount', 'tip_amount', 'tolls_amount', 'trip_distance', 'VendorID']\n",
    "\n",
    "# standardize (by calculating the zscore) so our data has mean 0 and var 1\n",
    "# alternatively, you can use sklearn's StandardScalar\n",
    "from scipy.stats import zscore\n",
    "\n",
    "df_standard = df_filtered[x_cols].astype(float).apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:32:40.574820Z",
     "start_time": "2022-07-23T23:32:40.550695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>VendorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fare_amount  tip_amount  tolls_amount  trip_distance  VendorID\n",
       "mean       0.0000      0.0000       -0.0000        -0.0000    0.0000\n",
       "std        1.0000      1.0000        1.0000         1.0000    1.0000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format output to 4 decimal places\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "df_standard.describe().loc[['mean','std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `df_standard` has  $\\mu=0, \\sigma=1(=\\sigma^2)$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:32:40.869488Z",
     "start_time": "2022-07-23T23:32:40.576955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNet()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ElasticNet()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from glmnet import ElasticNet\n",
    "\n",
    "elastic_net_model = ElasticNet(alpha=1)\n",
    "elastic_net_model.fit(\n",
    "    df_standard.values, \n",
    "    # flatten the array (from 2d matrix to 1d vector) to remove the warning message:\n",
    "    # A column-vector y was passed when a 1d array was expected.\n",
    "    df_filtered[y_cols].values.flatten()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to look at the shrinking parameter $\\lambda$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:32:40.887577Z",
     "start_time": "2022-07-23T23:32:40.874226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambda value for LASSO: 0.1445383795152823\n"
     ]
    }
   ],
   "source": [
    "# this can be accessed using the .lambda_best_ method after fitting!\n",
    "print(f'Best lambda value for LASSO: {elastic_net_model.lambda_best_[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\lambda$ for `ElasticNet` is computed by using cross validation (iterative approach). \n",
    "\n",
    "What about our coefficients?\n",
    "- https://github.com/civisanalytics/python-glmnet/blob/master/glmnet/linear.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:32:40.903091Z",
     "start_time": "2022-07-23T23:32:40.891711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>19.7526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare_amount</th>\n",
       "      <td>12.0098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tip_amount</th>\n",
       "      <td>2.9705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolls_amount</th>\n",
       "      <td>1.6871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_distance</th>\n",
       "      <td>0.0984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VendorID</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Coefficient\n",
       "Intercept          19.7526\n",
       "fare_amount        12.0098\n",
       "tip_amount          2.9705\n",
       "tolls_amount        1.6871\n",
       "trip_distance       0.0984\n",
       "VendorID            0.0000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    index=['Intercept'] + x_cols, \n",
    "    data=[elastic_net_model.intercept_] + list(elastic_net_model.coef_), \n",
    "    columns=['Coefficient']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the results.\n",
    "\n",
    "If you want to run predictions with `ElasticNet`, you can use `elastic_net_model.predict(x)` to the predict a new set of observations by passing through the `x` matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with Spark\n",
    "Whilst using `sklearn` or `statsmodels` can be easier on a smaller sample size, using the full dataset can be quite memory intensive. For those looking to use larger datasets, using the `pyspark.ml` library may prove useful.\n",
    "\n",
    "We'll go back to the first linear model example that we did with `statsmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:32:44.424368Z",
     "start_time": "2022-07-23T23:32:40.906526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/24 09:32:42 WARN Utils: Your hostname, NeonEx resolves to a loopback address: 127.0.1.1; using 172.18.90.123 instead (on interface eth0)\n",
      "22/07/24 09:32:42 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/24 09:32:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/07/24 09:32:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/07/24 09:32:44 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName('MAST30034 Tutorial 3')\n",
    "    .config('spark.sql.repl.eagerEval.enabled', True) \n",
    "    .config('spark.sql.parquet.cacheMetadata', 'true')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:32:47.384062Z",
     "start_time": "2022-07-23T23:32:44.426239Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sdf = spark.read.parquet('../../data/tlc_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like correlation from the previous tutorial, we will need to assemble a single vector for `pyspark.ml` to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:32:49.416723Z",
     "start_time": "2022-07-23T23:32:47.385505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " features     | [14.5,3.65,0.0,3.8,1.0] \n",
      " total_amount | 21.95                   \n",
      "-RECORD 1-------------------------------\n",
      " features     | [8.0,4.0,0.0,2.1,1.0]   \n",
      " total_amount | 13.3                    \n",
      "-RECORD 2-------------------------------\n",
      " features     | [7.5,1.76,0.0,0.97,2.0] \n",
      " total_amount | 10.56                   \n",
      "-RECORD 3-------------------------------\n",
      " features     | [8.0,0.0,0.0,1.09,2.0]  \n",
      " total_amount | 11.8                    \n",
      "-RECORD 4-------------------------------\n",
      " features     | [23.5,3.0,0.0,4.3,2.0]  \n",
      " total_amount | 30.3                    \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VectorAssembler creates new vectors from existing columns\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "features = 'features'\n",
    "input_cols = ['fare_amount', 'tip_amount', 'tolls_amount', 'trip_distance', 'VendorID']\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    # which column to combine\n",
    "    inputCols=input_cols, \n",
    "    # How should the combined columns be named\n",
    "    outputCol=features\n",
    ")\n",
    "\n",
    "model_sdf = assembler.transform(sdf.dropna('any'))\n",
    "\n",
    "# Display the features and targets for our model\n",
    "model_sdf.select('features', 'total_amount').show(5, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll start to notice that the PySpark API mirrors `sklearn`, hopefully, this doesn't seem to foreign.\n",
    "\n",
    "Pyspark Docs: https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html\n",
    "\n",
    "This implementation supports both OLS, Ridge, LASSO, and Elastic Net. You can change between the models by specifying the `elasticNetParam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:33:01.434831Z",
     "start_time": "2022-07-23T23:32:49.419932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/24 09:32:49 WARN Instrumentation: [87b21d05] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/07/24 09:32:50 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/07/24 09:32:50 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/24 09:32:57 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lm = LinearRegression(\n",
    "    featuresCol='features', \n",
    "    labelCol='total_amount'\n",
    ").fit(model_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:33:01.469090Z",
     "start_time": "2022-07-23T23:33:01.437421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>3.3832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare_amount</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tip_amount</th>\n",
       "      <td>1.0423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolls_amount</th>\n",
       "      <td>1.0224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_distance</th>\n",
       "      <td>-0.0057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VendorID</th>\n",
       "      <td>0.0071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               coefficient\n",
       "intercept           3.3832\n",
       "fare_amount         1.0000\n",
       "tip_amount          1.0423\n",
       "tolls_amount        1.0224\n",
       "trip_distance      -0.0057\n",
       "VendorID            0.0071"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access coefficients\n",
    "pd.DataFrame(\n",
    "    data=[lm.intercept] + list(lm.coefficients),\n",
    "    index=['intercept'] + input_cols,\n",
    "    columns=['coefficient']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through a single prediction from the record above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:33:01.785611Z",
     "start_time": "2022-07-23T23:33:01.471429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------\n",
      " total_amount  | 21.95 \n",
      " fare_amount   | 14.5  \n",
      " tip_amount    | 3.65  \n",
      " tolls_amount  | 0.0   \n",
      " trip_distance | 3.8   \n",
      " VendorID      | 1     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example record to predict\n",
    "sdf.select('total_amount', *input_cols).limit(1).show(vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:33:02.038024Z",
     "start_time": "2022-07-23T23:33:01.787635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------\n",
      " features | [14.5,3.65,0.0,3.8,1.0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocess for predictions\n",
    "predict_test = sdf.select(*input_cols).limit(1)\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=input_cols, \n",
    "    outputCol=features\n",
    ")\n",
    "\n",
    "predict_sdf = assembler.transform(predict_test).select(features)\n",
    "\n",
    "predict_sdf.show(1, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `lm.transform()` to predict an `sdf` containing a single vector of features as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:33:02.236168Z",
     "start_time": "2022-07-23T23:33:02.040148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------\n",
      " features   | [14.5,3.65,0.0,3.8,1.0] \n",
      " prediction | 21.672853184603834      \n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lm.transform(predict_sdf)\n",
    "predictions.show(vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the original record and compare the prediction vs true value. \n",
    "\n",
    "For evaluation metrics, you can use the `.summary` method. See https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegressionModel.html?highlight=ml%20summary%20regression#pyspark.ml.regression.LinearRegressionModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:33:02.244182Z",
     "start_time": "2022-07-23T23:33:02.238160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999718709807739"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r2 example\n",
    "lm.summary.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:33:02.253166Z",
     "start_time": "2022-07-23T23:33:02.247011Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LinearRegressionTrainingSummary in module pyspark.ml.regression object:\n",
      "\n",
      "class LinearRegressionTrainingSummary(LinearRegressionSummary)\n",
      " |  LinearRegressionTrainingSummary(java_obj: Union[ForwardRef('JavaObject'), NoneType] = None)\n",
      " |  \n",
      " |  Linear regression training results. Currently, the training summary ignores the\n",
      " |  training weights except for the objective trace.\n",
      " |  \n",
      " |  .. versionadded:: 2.0.0\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LinearRegressionTrainingSummary\n",
      " |      LinearRegressionSummary\n",
      " |      pyspark.ml.wrapper.JavaWrapper\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  objectiveHistory\n",
      " |      Objective function (scaled loss + regularization) at each\n",
      " |      iteration.\n",
      " |      This value is only available when using the \"l-bfgs\" solver.\n",
      " |      \n",
      " |      .. versionadded:: 2.0.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      LinearRegression.solver\n",
      " |  \n",
      " |  totalIterations\n",
      " |      Number of training iterations until termination.\n",
      " |      This value is only available when using the \"l-bfgs\" solver.\n",
      " |      \n",
      " |      .. versionadded:: 2.0.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      LinearRegression.solver\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from LinearRegressionSummary:\n",
      " |  \n",
      " |  coefficientStandardErrors\n",
      " |      Standard error of estimated coefficients and intercept.\n",
      " |      This value is only available when using the \"normal\" solver.\n",
      " |      \n",
      " |      If :py:attr:`LinearRegression.fitIntercept` is set to True,\n",
      " |      then the last element returned corresponds to the intercept.\n",
      " |      \n",
      " |      .. versionadded:: 2.0.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      LinearRegression.solver\n",
      " |  \n",
      " |  degreesOfFreedom\n",
      " |      Degrees of freedom.\n",
      " |      \n",
      " |      .. versionadded:: 2.2.0\n",
      " |  \n",
      " |  devianceResiduals\n",
      " |      The weighted residuals, the usual residuals rescaled by the\n",
      " |      square root of the instance weights.\n",
      " |      \n",
      " |      .. versionadded:: 2.0.0\n",
      " |  \n",
      " |  explainedVariance\n",
      " |      Returns the explained variance regression score.\n",
      " |      explainedVariance = :math:`1 - \\frac{variance(y - \\hat{y})}{variance(y)}`\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This ignores instance weights (setting all to 1.0) from\n",
      " |      `LinearRegression.weightCol`. This will change in later Spark\n",
      " |      versions.\n",
      " |      \n",
      " |      For additional information see\n",
      " |      `Explained variation on Wikipedia \\\n",
      " |      <http://en.wikipedia.org/wiki/Explained_variation>`_\n",
      " |      \n",
      " |      .. versionadded:: 2.0.0\n",
      " |  \n",
      " |  featuresCol\n",
      " |      Field in \"predictions\" which gives the features of each instance\n",
      " |      as a vector.\n",
      " |      \n",
      " |      .. versionadded:: 2.0.0\n",
      " |  \n",
      " |  labelCol\n",
      " |      Field in \"predictions\" which gives the true label of each\n",
      " |      instance.\n",
      " |      \n",
      " |      .. versionadded:: 2.0.0\n",
      " |  \n",
      " |  meanAbsoluteError\n",
      " |      Returns the mean absolute error, which is a risk function\n",
      " |      corresponding to the expected value of the absolute error\n",
      " |      loss or l1-norm loss.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This ignores instance weights (setting all to 1.0) from\n",
      " |      `LinearRegression.weightCol`. This will change in later Spark\n",
      " |      versions.\n",
      " |      \n",
      " |      .. versionadded:: 2.0.0\n",
      " |  \n",
      " |  meanSquaredError\n",
      " |      Returns the mean squared error, which is a risk function\n",
      " |      corresponding to the expected value of the squared error\n",
      " |      loss or quadratic loss.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This ignores instance weights (setting all to 1.0) from\n",
      " |      `LinearRegression.weightCol`. This will change in later Spark\n",
      " |      versions.\n",
      " |      \n",
      " |      .. versionadded:: 2.0.0\n",
      " |  \n",
      " |  numInstances\n",
      " |      Number of instances in DataFrame predictions\n",
      " |      \n",
      " |      .. versionadded:: 2.0.0\n",
      " |  \n",
      " |  pValues\n",
      " |      Two-sided p-value of estimated coefficients and intercept.\n",
      " |      This value is only available when using the \"normal\" solver.\n",
      " |      \n",
      " |      If :py:attr:`LinearRegression.fitIntercept` is set to True,\n",
      " |      then the last element returned corresponds to the intercept.\n",
      " |      \n",
      " |      .. versionadded:: 2.0.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      LinearRegression.solver\n",
      " |  \n",
      " |  predictionCol\n",
      " |      Field in \"predictions\" which gives the predicted value of\n",
      " |      the label at each instance.\n",
      " |      \n",
      " |      .. versionadded:: 2.0.0\n",
      " |  \n",
      " |  predictions\n",
      " |      Dataframe outputted by the model's `transform` method.\n",
      " |      \n",
      " |      .. versionadded:: 2.0.0\n",
      " |  \n",
      " |  r2\n",
      " |      Returns R^2, the coefficient of determination.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This ignores instance weights (setting all to 1.0) from\n",
      " |      `LinearRegression.weightCol`. This will change in later Spark\n",
      " |      versions.\n",
      " |      \n",
      " |      See also `Wikipedia coefficient of determination         <http://en.wikipedia.org/wiki/Coefficient_of_determination>`_\n",
      " |      \n",
      " |      .. versionadded:: 2.0.0\n",
      " |  \n",
      " |  r2adj\n",
      " |      Returns Adjusted R^2, the adjusted coefficient of determination.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This ignores instance weights (setting all to 1.0) from\n",
      " |      `LinearRegression.weightCol`. This will change in later Spark versions.\n",
      " |      \n",
      " |      `Wikipedia coefficient of determination, Adjusted R^2         <https://en.wikipedia.org/wiki/Coefficient_of_determination#Adjusted_R2>`_\n",
      " |      \n",
      " |      .. versionadded:: 2.4.0\n",
      " |  \n",
      " |  residuals\n",
      " |      Residuals (label - predicted value)\n",
      " |      \n",
      " |      .. versionadded:: 2.0.0\n",
      " |  \n",
      " |  rootMeanSquaredError\n",
      " |      Returns the root mean squared error, which is defined as the\n",
      " |      square root of the mean squared error.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This ignores instance weights (setting all to 1.0) from\n",
      " |      `LinearRegression.weightCol`. This will change in later Spark\n",
      " |      versions.\n",
      " |      \n",
      " |      .. versionadded:: 2.0.0\n",
      " |  \n",
      " |  tValues\n",
      " |      T-statistic of estimated coefficients and intercept.\n",
      " |      This value is only available when using the \"normal\" solver.\n",
      " |      \n",
      " |      If :py:attr:`LinearRegression.fitIntercept` is set to True,\n",
      " |      then the last element returned corresponds to the intercept.\n",
      " |      \n",
      " |      .. versionadded:: 2.0.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      LinearRegression.solver\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pyspark.ml.wrapper.JavaWrapper:\n",
      " |  \n",
      " |  __del__(self) -> None\n",
      " |  \n",
      " |  __init__(self, java_obj: Union[ForwardRef('JavaObject'), NoneType] = None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pyspark.ml.wrapper.JavaWrapper:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if you want to see the definitive list of all evaluation metrics accessible from lm.summary\n",
    "help(lm.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Notes for Revision\n",
    "#### What is the Bias-Variance tradeoff with respect to linear models:\n",
    "- Less parameters = less variance but more bias\n",
    "- More parameters = more variance but less bias\n",
    "- The goal depends on the problem, but generally we want an even variance and bias (intersection).\n",
    "\n",
    "\n",
    "#### Is using regression on X attribute / specific dataset even a good choice...?\n",
    "- The answer is yes, it is a good choice *to try*\n",
    "- BUT also try other methods...\n",
    "\n",
    "\n",
    "#### What are the pros and cons of stepwise regression?\n",
    "- Forward Selection (start from nothing and end until significant)\n",
    "- Backward Elimination (start with everything and end until no more can be removed)\n",
    "- Not always the best results...\n",
    "\n",
    "\n",
    "#### What is best subset regression and the pros and cons of it?\n",
    "- A brute-force like method of fitting *all possible regressions* or *all possible models*\n",
    "- Unlike stepwise, this method fits all possible models based on the variables specified, so you will get the best model possible\n",
    "![a_secret_easter_egg_i_like_apples](https://i.kym-cdn.com/photos/images/newsfeed/001/718/138/147.jpg)\n",
    "\n",
    "\n",
    "\n",
    "#### What is an assumption we make when we fit linear regression models?\n",
    "- Make sure the input matrix is full rank.\n",
    "  - Question: _What happens when input matrix is not full rank?_\n",
    "- Well, the data has to be linearly separable. \n",
    "- Does this also apply to other models too...? (Recall SVM and kernel function which we can use)\n",
    "- Perhaps another model might suit the dataset... (Trees, Neural Networks, Clustering, etc...)\n",
    "\n",
    "\n",
    "#### If you were to use a decision tree, how would you compare between two different fits? \n",
    "- Look at Gini Impurity (probability of an incorrectly classified instance)\n",
    "\n",
    "\n",
    "#### How about baselines or other predictive machine learning models?\n",
    "- Precision, Recall, Classification Accuracy...\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Fitting a GLM with Python\n",
    "**Since MAST30027 is not a pre-requisuite, we will not cover this nor do we expect students to use GLMs. However, those who wish to experiment with GLMs using Python may go through this section.**\n",
    "\n",
    "Let's go through an example:\n",
    "- The `passenger_count` attribute is discrete and non-negative. If we were to predict it, a linear model will not be sufficient. \n",
    "- We know that a Poisson distribution takes in non-negative integer values, so we can use the Poisson family of GLMs to model this. \n",
    "- We will use `total_amount, trip_distance, VendorID` as our regressors.\n",
    "\n",
    "Summary:\n",
    "- GLM's allow us to express relationships in a linear and additive way like normal linear regression.\n",
    "- However, it might be the case that the underlying true relationship is neither linear nor additive. \n",
    "- The transformation is done through a *link function* (in this case, Poisson).\n",
    "\n",
    "Why would we use try and use Poisson? The distribution of `passenger_count` is frequency based greater than 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T23:33:02.517496Z",
     "start_time": "2022-07-23T23:33:02.256226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:        passenger_count   No. Observations:               118876\n",
      "Model:                            GLM   Df Residuals:                   118872\n",
      "Model Family:                 Poisson   Df Model:                            3\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:            -1.5748e+05\n",
      "Date:                Sun, 24 Jul 2022   Deviance:                       59171.\n",
      "Time:                        09:33:02   Pearson chi2:                 7.85e+04\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):            0.01426\n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept            0.3702      0.004     88.008      0.000       0.362       0.378\n",
      "VendorID[T.True]    -0.2249      0.006    -39.938      0.000      -0.236      -0.214\n",
      "total_amount         0.0011      0.000      4.295      0.000       0.001       0.002\n",
      "trip_distance     5.558e-05      0.001      0.064      0.949      -0.002       0.002\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.api import families\n",
    "\n",
    "# convert VendorID to categorical\n",
    "df['VendorID'] = df['VendorID'] == 1\n",
    "\n",
    "# statsmodels glm\n",
    "fit = glm(\n",
    "    formula=\"passenger_count ~ total_amount + trip_distance + VendorID\",\n",
    "    data=df, \n",
    "    family=families.Poisson()\n",
    ").fit()\n",
    "\n",
    "print(fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "8684bbbdedfc9b42b999b1d31697a8d5e570e18b51cdd65265af4b894fa44cb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
